{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training to advection terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import jax_cfd.base as cfd\n",
    "from jax_cfd.base import advection\n",
    "from jax_cfd.ml import towers\n",
    "import jax_cfd.ml.train_utils as train_utils\n",
    "from jax_cfd.base import finite_differences as fd\n",
    "from jax_cfd.base import grids\n",
    "\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import xarray\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "# from jax_cfd.ml.diego_model_utils import SaveObject, forward_pass_module\n",
    "import jax_cfd.ml.diego_preprocessing as preprocessing\n",
    "import jax_cfd.ml.diego_train_functions as training\n",
    "from jax_cfd.ml import nonlinearities\n",
    "import jax_cfd.ml.diego_cnn_bcs as bcs\n",
    "\n",
    "import jax_cfd.ml.newSaveObject as saving\n",
    "import jax_cfd.ml.diego_towers as mytowers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "import time\n",
    "\n",
    "import tree_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this allows me to reload a module without having to interrupt the kernel\n",
    "# import importlib\n",
    "# importlib.reload()\n",
    "# importlib.reload(from jax_cfd.ml.diego_train_functions import *)\n",
    "# importlib.reload(from jax_cfd.ml import nonlinearities)\n",
    "# importlib.reload(from jax_cfd.ml.diego_cnn_bcs import *)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "file_name = '256x64_150_seconds_inner_1'\n",
    "data = xarray.open_dataset(f'../../creating_dataset/datasets/'+ file_name +'.nc', chunks={'time': '100MB'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# split by timestamps\n",
    "x_shape = len(data.x)\n",
    "y_shape = len(data.y)\n",
    "high_def = []\n",
    "for i in range(int(len(data.time))):\n",
    "    this_time = np.dstack([\n",
    "        jnp.array([data.u.isel(time = i)]).reshape(x_shape,y_shape),\n",
    "        jnp.array([data.v.isel(time = i)]).reshape(x_shape,y_shape)\n",
    "    ])\n",
    "    high_def.append(this_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt: \t\t0.015625\n",
      "outer_steps: \t9600\n",
      "inner_steps: \t1.0\n",
      "total_sim_time: 150.0\n",
      "removed points: 960\n",
      "\n",
      "\n",
      "step = 10\n",
      "Training dataset shape: \n",
      "\t(864, 256, 64, 2)\n"
     ]
    }
   ],
   "source": [
    "#warm up time (may want to discard initial stages of simulation since not really representative of turbulent flow?)\n",
    "dt = float(data.time[0].values)\n",
    "\n",
    "outer_steps = len(data.time.values)\n",
    "\n",
    "inner_steps = (data.time[1].values-data.time[0].values)/dt\n",
    "\n",
    "total_sim_time = outer_steps*inner_steps*dt\n",
    "print(\"dt: \\t\\t\" + str(dt))\n",
    "print(\"outer_steps: \\t\" + str(outer_steps))\n",
    "print(\"inner_steps: \\t\" + str(inner_steps))\n",
    "print(\"total_sim_time: \" + str(total_sim_time))\n",
    "\n",
    "warm_up = 15 #seconds\n",
    "warm_index = int(warm_up/total_sim_time * outer_steps // 1)\n",
    "print(\"removed points: \" + str(warm_index))\n",
    "high_def = high_def[warm_index:]\n",
    "\n",
    "print(\"\\n\")\n",
    "step = 10\n",
    "high_def = high_def[0::step]\n",
    "print(\"step = \" + str(step))\n",
    "print(\"Training dataset shape: \") # (frames, x, y, input channels)\n",
    "print(\"\\t\" + str(np.shape(high_def)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convect(v):  # pylint: disable=function-redefined\n",
    "      return tuple(\n",
    "          advection.advect_van_leer(u, v, dt) for u in v)\n",
    "    \n",
    "convection = cfd.equations._wrap_term_as_vector(convect, name='convection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeForAdvection(v):\n",
    "    mygrid = (grids.GridVariable(array = grids.GridArray(data = v[:,:,0], \n",
    "                                            offset = (1.0, 0.5), \n",
    "                                            grid=grids.Grid(\n",
    "                                                shape=(256, 64),  \n",
    "                                                domain=((0.0, 8.0), (0.0, 2.0)) ) ),\n",
    "#                        bc=cfd.boundaries.channel_flow_boundary_conditions(ndim=2)\n",
    "                        bc = cfd.boundaries.periodic_boundary_conditions(2)\n",
    "                   ),\n",
    "             grids.GridVariable(array = grids.GridArray(data = v[:,:,1], \n",
    "                                            offset = (0.5, 1.0),\n",
    "                                            grid=grids.Grid(\n",
    "                                                shape=(256, 64),  \n",
    "                                                domain=((0.0, 8.0), (0.0, 2.0)) ) ),\n",
    "#                        bc=cfd.boundaries.channel_flow_boundary_conditions(ndim=2)\n",
    "                        bc = cfd.boundaries.periodic_boundary_conditions(2)\n",
    "                   )\n",
    "           )\n",
    "    return tree_math.Vector(mygrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_advected = []\n",
    "for field in high_def:\n",
    "    advected = convection(reshapeForAdvection(field))\n",
    "    vel = 0\n",
    "    uadv = advected.tree_flatten()[0][0][vel].data\n",
    "    vel = 1\n",
    "    vadv = advected.tree_flatten()[0][0][vel].data\n",
    "    this_time = jnp.dstack([\n",
    "            jnp.array(uadv),\n",
    "            jnp.array(vadv)\n",
    "        ])\n",
    "    all_advected.append(this_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create X dataset: \n",
      "CPU times: user 184 ms, sys: 15.9 ms, total: 200 ms\n",
      "Wall time: 200 ms\n",
      "\n",
      "Create Y dataset: \n",
      "CPU times: user 903 ms, sys: 7.89 ms, total: 911 ms\n",
      "Wall time: 916 ms\n",
      "\n",
      "Shapes of all datasets\n",
      "(691, 64, 16, 2)\n",
      "(691, 64, 16, 2)\n",
      "(173, 64, 16, 2)\n",
      "(173, 64, 16, 2)\n"
     ]
    }
   ],
   "source": [
    "#split into train and test\n",
    "\n",
    "split = 0.8\n",
    "split = int(len(high_def)*split//1)\n",
    "random.shuffle(high_def)\n",
    "\n",
    "factor = 4\n",
    "\n",
    "print(\"Create X dataset: \")\n",
    "%time X_dataset = preprocessing.creatingDataset(high_def,preprocessing.sampling,factor)\n",
    "\n",
    "print(\"\\nCreate Y dataset: \")\n",
    "padding = [1,1]\n",
    "%time Y_dataset = preprocessing.creatingDataset(all_advected,preprocessing.sampling,factor)\n",
    "\n",
    "# %time Y_dataset = calculateResiduals(X_dataset,Y_dataset)\n",
    "\n",
    "\n",
    "X_train = X_dataset[:split]\n",
    "Y_train = Y_dataset[:split]\n",
    "\n",
    "X_test = X_dataset[split:]\n",
    "Y_test = Y_dataset[split:]\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nPadding all datasets: \")\n",
    "# padding = [1,1] #this is for a 3 by 3 kernel, find a better way to define this (so not redifined when creating CNN)\n",
    "# %time X_train = padXDataset(X_train,padding)\n",
    "# %time Y_train = padYDatasetNew(Y_train,padding,conditions)\n",
    "\n",
    "# %time X_test = padXDataset(X_test,padding)\n",
    "# %time Y_test = padYDataset(Y_test,padding,conditions)\n",
    "\n",
    "print(\"\\nShapes of all datasets\")\n",
    "training.printAllShapes(X_train,Y_train, X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet(x):\n",
    "    cnn = mytowers.CNN(CNN_specs)\n",
    "    return cnn(x)\n",
    "\n",
    "CNN_specs = {\n",
    "    \"hidden_channels\" : 25,\n",
    "    \"hidden_layers\" : 6,\n",
    "    \"nonlinearity\" : \"relu\",\n",
    "    \"num_output_channels\" : 2\n",
    "}\n",
    "input_channels = 2\n",
    "\n",
    "# CNN_specs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_pass = hk.without_apply_rng(hk.transform(ConvNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of all datasets\n",
      "(691, 64, 16, 2)\n",
      "(691, 64, 16, 2)\n",
      "(173, 64, 16, 2)\n",
      "(173, 64, 16, 2)\n",
      "\n",
      "\n",
      "\n",
      "Start time: 15:24:21\n",
      "Epoch 1/50\n",
      "\tmse : 0.032956\t\tval mse : 0.063758\tEstimated end time: 15:52:55\n",
      "\n",
      "\n",
      "Epoch 2/50\n",
      "\tmse : 0.032945\t\tval mse : 0.063748\tEstimated end time: 16:02:24\n",
      "\n",
      "\n",
      "Epoch 3/50\n",
      "\tmse : 0.032935\t\tval mse : 0.063739\tEstimated end time: 16:07:23\n",
      "\n",
      "\n",
      "Epoch 4/50\n",
      "\tmse : 0.032925\t\tval mse : 0.063730\tEstimated end time: 16:10:03\n",
      "\n",
      "\n",
      "Epoch 5/50\n",
      "\tmse : 0.032916\t\tval mse : 0.063721\tEstimated end time: 16:11:59\n",
      "\n",
      "\n",
      "Epoch 6/50\n",
      "\tmse : 0.032907\t\tval mse : 0.063712\tEstimated end time: 16:13:13\n",
      "\n",
      "\n",
      "Epoch 7/50\n",
      "\tmse : 0.032898\t\tval mse : 0.063703\tEstimated end time: 16:14:42\n",
      "\n",
      "\n",
      "Epoch 8/50\n",
      "\tmse : 0.032888\t\tval mse : 0.063694\tEstimated end time: 16:15:51\n",
      "\n",
      "\n",
      "Epoch 9/50\n",
      "\tmse : 0.032879\t\tval mse : 0.063685\tEstimated end time: 16:16:58\n",
      "\n",
      "\n",
      "Epoch 10/50\n",
      "\tmse : 0.032870\t\tval mse : 0.063676\tEstimated end time: 16:17:37\n",
      "\n",
      "\n",
      "Epoch 11/50\n",
      "\tmse : 0.032861\t\tval mse : 0.063667\tEstimated end time: 16:18:16\n",
      "\n",
      "\n",
      "Epoch 12/50\n",
      "\tmse : 0.032852\t\tval mse : 0.063658\tEstimated end time: 16:18:35\n",
      "\n",
      "\n",
      "Epoch 13/50\n",
      "\tmse : 0.032843\t\tval mse : 0.063649\tEstimated end time: 16:18:55\n",
      "\n",
      "\n",
      "Epoch 14/50\n",
      "\tmse : 0.032834\t\tval mse : 0.063641\tEstimated end time: 16:19:09\n",
      "\n",
      "\n",
      "Epoch 15/50\n",
      "\tmse : 0.032825\t\tval mse : 0.063632\tEstimated end time: 16:19:24\n",
      "\n",
      "\n",
      "Epoch 16/50\n",
      "\tmse : 0.032817\t\tval mse : 0.063624\tEstimated end time: 16:19:33\n",
      "\n",
      "\n",
      "Epoch 17/50\n",
      "\tmse : 0.032808\t\tval mse : 0.063615\tEstimated end time: 16:19:43\n",
      "\n",
      "\n",
      "Epoch 18/50\n",
      "\tmse : 0.032800\t\tval mse : 0.063607\tEstimated end time: 16:19:48\n",
      "\n",
      "\n",
      "Epoch 19/50\n",
      "\tmse : 0.032792\t\tval mse : 0.063599\tEstimated end time: 16:19:54\n",
      "\n",
      "\n",
      "Epoch 20/50\n",
      "\tmse : 0.032784\t\tval mse : 0.063592\tEstimated end time: 16:19:55\n",
      "\n",
      "\n",
      "Epoch 21/50\n",
      "\tmse : 0.032777\t\tval mse : 0.063584\tEstimated end time: 16:19:59\n",
      "\n",
      "\n",
      "Epoch 22/50\n",
      "\tmse : 0.032769\t\tval mse : 0.063576\tEstimated end time: 16:20:04\n",
      "\n",
      "\n",
      "Epoch 23/50\n",
      "\tmse : 0.032762\t\tval mse : 0.063569\tEstimated end time: 16:20:25\n",
      "\n",
      "\n",
      "Epoch 24/50\n",
      "\tmse : 0.032755\t\tval mse : 0.063562\tEstimated end time: 16:20:36\n",
      "\n",
      "\n",
      "Epoch 25/50\n",
      "\tmse : 0.032748\t\tval mse : 0.063555\tEstimated end time: 16:20:43\n",
      "\n",
      "\n",
      "Epoch 26/50\n",
      "\tmse : 0.032741\t\tval mse : 0.063548\tEstimated end time: 16:20:46\n",
      "\n",
      "\n",
      "Epoch 27/50\n",
      "\tmse : 0.032734\t\tval mse : 0.063541\tEstimated end time: 16:20:50\n",
      "\n",
      "\n",
      "Epoch 28/50\n",
      "\tmse : 0.032728\t\tval mse : 0.063535\tEstimated end time: 16:20:52\n",
      "\n",
      "\n",
      "Epoch 29/50\n",
      "\tmse : 0.032722\t\tval mse : 0.063528\tEstimated end time: 16:20:56\n",
      "\n",
      "\n",
      "Epoch 30/50\n",
      "\tmse : 0.032715\t\tval mse : 0.063522\tEstimated end time: 16:20:56\n",
      "\n",
      "\n",
      "Epoch 31/50\n",
      "\tmse : 0.032709\t\tval mse : 0.063516\tEstimated end time: 16:21:00\n",
      "\n",
      "\n",
      "Epoch 32/50\n",
      "\tmse : 0.032703\t\tval mse : 0.063509\tEstimated end time: 16:21:00\n",
      "\n",
      "\n",
      "Epoch 33/50\n",
      "\tmse : 0.032697\t\tval mse : 0.063503\tEstimated end time: 16:21:15\n",
      "\n",
      "\n",
      "Epoch 34/50\n",
      "\tmse : 0.032691\t\tval mse : 0.063497\tEstimated end time: 16:21:24\n",
      "\n",
      "\n",
      "Epoch 35/50\n",
      "\tmse : 0.032685\t\tval mse : 0.063491\tEstimated end time: 16:21:35\n",
      "\n",
      "\n",
      "Epoch 36/50\n"
     ]
    }
   ],
   "source": [
    "instance = training.MyTraining(X_train,Y_train,X_test,Y_test,\n",
    "                      jax.random.PRNGKey(40), #rng_key\n",
    "                      input_channels=2,\n",
    "                      epochs = 50,\n",
    "                      printEvery=1,#epochs\n",
    "                      learning_rates=training.staggeredLearningRate((50,0.1),(20,0.01),(11,0.001)), #iterated over batches\n",
    "                      batch_size=len(X_train)//2+1, # number or len(X_train)\n",
    "                      validateEvery=1,\n",
    "                      params=None,\n",
    "                      forward_pass=forward_pass,\n",
    "                      tol = 1e-10)\n",
    "\n",
    "%time instance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m batches \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(instance\u001b[38;5;241m.\u001b[39mlosses))\n\u001b[0;32m----> 2\u001b[0m val_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_losses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m batches_val \u001b[38;5;241m=\u001b[39m batches[::val_step]\u001b[38;5;241m+\u001b[39mval_step\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(batches\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,instance\u001b[38;5;241m.\u001b[39mlosses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "batches = np.arange(len(instance.losses))\n",
    "val_step = len(instance.losses)//len(instance.val_losses)\n",
    "\n",
    "batches_val = batches[::val_step]+val_step\n",
    "plt.plot(batches+1,instance.losses, label=\"training\")\n",
    "plt.plot(batches_val,instance.val_losses,label=\"validation\")\n",
    "plt.ylabel(\"mse\")\n",
    "plt.xlabel(\"batches\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"left for lunch, please save me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toSave = saving.newSaveObject(instance.params,instance.losses,instance.val_losses,description,CNN_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./../models/final_models/advection_1.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,\"wb\") as f:\n",
    "    pickle.dump(toSave,f)\n",
    "\n",
    "del save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path,'rb',) as pickle_file:\n",
    "    loaded = pickle.load(pickle_file)\n",
    "    CNN_specs = loaded.CNN_specs\n",
    "    loaded.forward_pass = hk.without_apply_rng(hk.transform(ConvNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PNAS_codes]",
   "language": "python",
   "name": "conda-env-PNAS_codes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
